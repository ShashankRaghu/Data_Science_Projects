{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, we read the folder names for training and validation. We also set the `batch_size` here. Note that we set the batch size in such a way that we are able to use the GPU in full capacity. We can keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('/notebooks/storage/Final_data/Collated_training/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('/notebooks/storage/Final_data/Collated_training/val.csv').readlines())\n",
    "batch_size = 50 #experiment with the batch size\n",
    "\n",
    "dim_x = 120\n",
    "dim_y = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. In the generator, we are going to preprocess the images as we have images of 2 different dimensions as well as create a batch of video frames. We have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size, abalation=None):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = [x for x in range(0,30,2)]\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size    # calculate the number of batches\n",
    "        if abalation is not None:\n",
    "            num_batches = abalation//batch_size\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,len(img_idx),dim_x,dim_y,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = imresize(image, (dim_x ,dim_y, 3))\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (image[:,:,0]-np.min(image[:,:,0]))/(np.max(image[:,:,0])-np.min(image[:,:,0]))   #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = (image[:,:,1]-np.min(image[:,:,1]))/(np.max(image[:,:,1])-np.min(image[:,:,1]))   #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (image[:,:,2]-np.min(image[:,:,2]))/(np.max(image[:,:,2])-np.min(image[:,:,2]))   #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        #code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list)%batch_size) != 0:\n",
    "            remaining_batch = len(folder_list)%batch_size\n",
    "            if abalation is not None:\n",
    "                remaining_batch = abalation%batch_size\n",
    "            rem_batch_data = np.zeros((remaining_batch,len(img_idx),dim_x,dim_y,3))\n",
    "            rem_batch_labels = np.zeros((remaining_batch,5))\n",
    "            for folder in range(remaining_batch):\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (num_batches*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (num_batches*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "\n",
    "                    image = imresize(image, (dim_x ,dim_y, 3))\n",
    "                    rem_batch_data[folder,idx,:,:,0] = (image[:,:,0]-np.min(image[:,:,0]))/(np.max(image[:,:,0])-np.min(image[:,:,0]))   #normalise and feed in the image\n",
    "                    rem_batch_data[folder,idx,:,:,1] = (image[:,:,1]-np.min(image[:,:,1]))/(np.max(image[:,:,1])-np.min(image[:,:,1]))   #normalise and feed in the image\n",
    "                    rem_batch_data[folder,idx,:,:,2] = (image[:,:,2]-np.min(image[:,:,2]))/(np.max(image[:,:,2])-np.min(image[:,:,2]))   #normalise and feed in the image\n",
    "\n",
    "                rem_batch_labels[folder, int(t[folder + (num_batches*batch_size)].strip().split(';')[2])] = 1\n",
    "                yield rem_batch_data, rem_batch_labels #you yield the batch_data and the batch_labels, remember what does yield do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 50\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = '/notebooks/storage/Final_data/Collated_training/train'\n",
    "val_path = '/notebooks/storage/Final_data/Collated_training/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 50 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here we make the model using different functionalities that Keras provides. We will use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. The last layer is the softmax layer. We should design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (15, dim_x, dim_y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, LSTM, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "#write your model here\n",
    "model = Sequential()\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', padding = 'same', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 3, 3)))\n",
    "\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 3, 3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have written the model, the next step is to `compile` the model. When we print the `summary` of the model, we'll see the total number of parameters we have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 15, 120, 120, 32)  2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 15, 120, 120, 32)  128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 7, 40, 40, 64)     55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 40, 40, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 3, 13, 13, 64)     0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32448)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               4153472   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 4,212,485\n",
      "Trainable params: 4,212,293\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = SGD(lr=0.001,clipvalue=1.0) #optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalation = None\n",
    "train_generator = generator(train_path, train_doc, batch_size, abalation=abalation)\n",
    "val_generator = generator(val_path, val_doc, batch_size, abalation=abalation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=2, min_lr=0.00001)  # write the REducelronplateau code here\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (abalation%batch_size) == 0:\n",
    "#     steps_per_epoch = int(abalation/batch_size)\n",
    "# else:\n",
    "#     steps_per_epoch = (abalation//batch_size) + 1\n",
    "\n",
    "# if (abalation%batch_size) == 0:\n",
    "#     validation_steps = int(abalation/batch_size)\n",
    "# else:\n",
    "#     validation_steps = (abalation//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, we'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 50\n",
      "Source path =  Project_data/train ; batch size = 50\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  app.launch_new_instance()\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14 [========================>.....] - ETA: 30s - loss: 4.0056 - categorical_accuracy: 0.2667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 198s 14s/step - loss: 3.5803 - categorical_accuracy: 0.2519 - val_loss: 1.3918 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-12-1909_17_35.246486/model-00001-3.75091-0.26094-1.39178-0.36000.h5\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.5037 - categorical_accuracy: 0.8267 - val_loss: 1.8203 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-12-1909_17_35.246486/model-00002-0.75791-0.71484-1.82034-0.34000.h5\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 70s 5s/step - loss: 1.0550 - categorical_accuracy: 0.5483 - val_loss: 1.2691 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-12-1909_17_35.246486/model-00003-1.16397-0.51443-1.26913-0.48000.h5\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.3514 - categorical_accuracy: 0.8833 - val_loss: 1.0921 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-12-1909_17_35.246486/model-00004-0.63429-0.76970-1.09210-0.55000.h5\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 58s 4s/step - loss: 0.8053 - categorical_accuracy: 0.6497 - val_loss: 1.4642 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-12-1909_17_35.246486/model-00005-0.93885-0.61553-1.46423-0.45000.h5\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.4181 - categorical_accuracy: 0.8397 - val_loss: 1.0265 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-12-1909_17_35.246486/model-00006-0.65208-0.73515-1.02650-0.54000.h5\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 46s 3s/step - loss: 0.4875 - categorical_accuracy: 0.7527 - val_loss: 1.3531 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-12-1909_17_35.246486/model-00007-0.62026-0.73243-1.35307-0.52000.h5\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 53s 4s/step - loss: 0.4010 - categorical_accuracy: 0.8527 - val_loss: 1.0608 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-12-1909_17_35.246486/model-00008-0.55616-0.79079-1.06080-0.53000.h5\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 38s 3s/step - loss: 0.3848 - categorical_accuracy: 0.8325 - val_loss: 1.2541 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-12-1909_17_35.246486/model-00009-0.46919-0.81471-1.25409-0.53000.h5\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 73s 5s/step - loss: 0.3462 - categorical_accuracy: 0.8924 - val_loss: 0.9392 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-12-1909_17_35.246486/model-00010-0.42427-0.86594-0.93916-0.61000.h5\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.1687 - categorical_accuracy: 0.9139 - val_loss: 1.0881 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-12-1909_17_35.246486/model-00011-0.23180-0.91126-1.08813-0.58000.h5\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 66s 5s/step - loss: 0.3134 - categorical_accuracy: 0.9035 - val_loss: 0.8869 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-12-1909_17_35.246486/model-00012-0.34496-0.89297-0.88692-0.61000.h5\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 10s 722ms/step - loss: 0.1103 - categorical_accuracy: 0.8788 - val_loss: 0.9361 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-12-1909_17_35.246486/model-00013-0.13847-0.89498-0.93608-0.63000.h5\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 73s 5s/step - loss: 0.2885 - categorical_accuracy: 0.8874 - val_loss: 1.1480 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-12-1909_17_35.246486/model-00014-0.29517-0.90950-1.14796-0.57000.h5\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1001 - categorical_accuracy: 0.9577 - val_loss: 0.8650 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-12-1909_17_35.246486/model-00015-0.17924-0.93359-0.86501-0.63000.h5\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 61s 4s/step - loss: 0.2015 - categorical_accuracy: 0.9257 - val_loss: 0.9378 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-12-1909_17_35.246486/model-00016-0.21432-0.94397-0.93777-0.61000.h5\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0913 - categorical_accuracy: 0.9862 - val_loss: 0.8232 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-12-1909_17_35.246486/model-00017-0.15400-0.97273-0.82319-0.66000.h5\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 53s 4s/step - loss: 0.1516 - categorical_accuracy: 0.9456 - val_loss: 0.9205 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-12-1909_17_35.246486/model-00018-0.17593-0.96311-0.92047-0.62000.h5\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 36s 3s/step - loss: 0.0940 - categorical_accuracy: 0.9910 - val_loss: 0.8719 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-12-1909_17_35.246486/model-00019-0.14104-0.98515-0.87185-0.61000.h5\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.1332 - categorical_accuracy: 0.9459 - val_loss: 0.9265 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-12-1909_17_35.246486/model-00020-0.15019-0.96372-0.92649-0.63000.h5\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 46s 3s/step - loss: 0.1039 - categorical_accuracy: 0.9926 - val_loss: 0.8222 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-12-1909_17_35.246486/model-00021-0.13503-0.98954-0.82217-0.67000.h5\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.0978 - categorical_accuracy: 0.9636 - val_loss: 0.8971 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-12-1909_17_35.246486/model-00022-0.12815-0.97548-0.89710-0.67000.h5\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 55s 4s/step - loss: 0.1119 - categorical_accuracy: 0.9884 - val_loss: 0.8325 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-12-1909_17_35.246486/model-00023-0.13383-0.98551-0.83248-0.66000.h5\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.0761 - categorical_accuracy: 0.9572 - val_loss: 0.8401 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-12-1909_17_35.246486/model-00024-0.09416-0.97270-0.84006-0.67000.h5\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 64s 5s/step - loss: 0.1116 - categorical_accuracy: 0.9971 - val_loss: 0.8162 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-12-1909_17_35.246486/model-00025-0.12075-0.99681-0.81618-0.66000.h5\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 11s 819ms/step - loss: 0.0659 - categorical_accuracy: 0.8588 - val_loss: 0.8742 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-12-1909_17_35.246486/model-00026-0.07472-0.88128-0.87416-0.64000.h5\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 71s 5s/step - loss: 0.1245 - categorical_accuracy: 0.9814 - val_loss: 0.8170 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-12-1909_17_35.246486/model-00027-0.12176-0.99246-0.81700-0.65000.h5\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0630 - categorical_accuracy: 0.9784 - val_loss: 0.8379 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-12-1909_17_35.246486/model-00028-0.07332-0.98438-0.83788-0.63000.h5\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 61s 4s/step - loss: 0.1187 - categorical_accuracy: 0.9409 - val_loss: 0.8805 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-12-1909_17_35.246486/model-00029-0.11358-0.97963-0.88053-0.63000.h5\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0718 - categorical_accuracy: 0.9939 - val_loss: 0.8182 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-12-1909_17_35.246486/model-00030-0.10383-0.98788-0.81816-0.66000.h5\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 51s 4s/step - loss: 0.1144 - categorical_accuracy: 0.9655 - val_loss: 0.8497 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00031: saving model to model_init_2020-12-1909_17_35.246486/model-00031-0.11098-0.98447-0.84967-0.65000.h5\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 35s 2s/step - loss: 0.0808 - categorical_accuracy: 1.0000 - val_loss: 0.8342 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00032: saving model to model_init_2020-12-1909_17_35.246486/model-00032-0.09297-1.00000-0.83423-0.65000.h5\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0845 - categorical_accuracy: 0.9563 - val_loss: 0.8270 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00033: saving model to model_init_2020-12-1909_17_35.246486/model-00033-0.10334-0.97959-0.82702-0.66000.h5\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 45s 3s/step - loss: 0.0693 - categorical_accuracy: 1.0000 - val_loss: 0.8149 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00034: saving model to model_init_2020-12-1909_17_35.246486/model-00034-0.08757-1.00000-0.81486-0.63000.h5\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.0972 - categorical_accuracy: 0.9681 - val_loss: 0.8384 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00035: saving model to model_init_2020-12-1909_17_35.246486/model-00035-0.09797-0.98365-0.83844-0.66000.h5\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 55s 4s/step - loss: 0.0957 - categorical_accuracy: 0.9985 - val_loss: 0.8159 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00036: saving model to model_init_2020-12-1909_17_35.246486/model-00036-0.10615-0.99819-0.81593-0.66000.h5\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.0618 - categorical_accuracy: 0.9679 - val_loss: 0.8191 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00037: saving model to model_init_2020-12-1909_17_35.246486/model-00037-0.06683-0.97952-0.81911-0.65000.h5\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 64s 5s/step - loss: 0.0891 - categorical_accuracy: 1.0000 - val_loss: 0.8136 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00038: saving model to model_init_2020-12-1909_17_35.246486/model-00038-0.09394-1.00000-0.81364-0.67000.h5\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 10s 721ms/step - loss: 0.0757 - categorical_accuracy: 0.9294 - val_loss: 0.8364 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00039: saving model to model_init_2020-12-1909_17_35.246486/model-00039-0.07985-0.94064-0.83641-0.70000.h5\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 70s 5s/step - loss: 0.1021 - categorical_accuracy: 0.9686 - val_loss: 0.8173 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00040: saving model to model_init_2020-12-1909_17_35.246486/model-00040-0.09697-0.99095-0.81730-0.68000.h5\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0911 - categorical_accuracy: 0.9838 - val_loss: 0.8174 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00041: saving model to model_init_2020-12-1909_17_35.246486/model-00041-0.08707-0.98828-0.81741-0.68000.h5\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 61s 4s/step - loss: 0.1111 - categorical_accuracy: 0.9633 - val_loss: 0.8239 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00042: saving model to model_init_2020-12-1909_17_35.246486/model-00042-0.10042-0.98812-0.82386-0.68000.h5\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0838 - categorical_accuracy: 1.0000 - val_loss: 0.8419 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00043: saving model to model_init_2020-12-1909_17_35.246486/model-00043-0.08403-1.00000-0.84192-0.68000.h5\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 51s 4s/step - loss: 0.1082 - categorical_accuracy: 0.9632 - val_loss: 0.8393 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00044: saving model to model_init_2020-12-1909_17_35.246486/model-00044-0.10133-0.98641-0.83931-0.68000.h5\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 35s 2s/step - loss: 0.0771 - categorical_accuracy: 0.9985 - val_loss: 0.8308 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00045: saving model to model_init_2020-12-1909_17_35.246486/model-00045-0.08237-0.99752-0.83083-0.69000.h5\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 41s 3s/step - loss: 0.1003 - categorical_accuracy: 0.9630 - val_loss: 0.8385 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00046: saving model to model_init_2020-12-1909_17_35.246486/model-00046-0.09715-0.98413-0.83847-0.67000.h5\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 44s 3s/step - loss: 0.0857 - categorical_accuracy: 1.0000 - val_loss: 0.8358 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00047: saving model to model_init_2020-12-1909_17_35.246486/model-00047-0.09283-1.00000-0.83581-0.67000.h5\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.0893 - categorical_accuracy: 0.9681 - val_loss: 0.8466 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00048: saving model to model_init_2020-12-1909_17_35.246486/model-00048-0.08771-0.98365-0.84664-0.66000.h5\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 53s 4s/step - loss: 0.0899 - categorical_accuracy: 0.9985 - val_loss: 0.8404 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00049: saving model to model_init_2020-12-1909_17_35.246486/model-00049-0.09240-0.99819-0.84041-0.68000.h5\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.0752 - categorical_accuracy: 0.9679 - val_loss: 0.8351 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00050: saving model to model_init_2020-12-1909_17_35.246486/model-00050-0.08173-0.97952-0.83506-0.68000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff46130fd68>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Model 1 we are getting a validation categorical accuracy of around 0.6800 and the validation loss between 0.8 and 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will add dropout in layers after flatten layer in Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', padding = 'same', input_shape=input_shape))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling3D(pool_size=(2, 3, 3)))\n",
    "\n",
    "model_2.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling3D(pool_size=(2, 3, 3)))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(128, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_3 (Conv3D)            (None, 15, 120, 120, 32)  2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 120, 120, 32)  128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 7, 40, 40, 64)     55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 40, 40, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 3, 13, 13, 64)     0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32448)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32448)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               4153472   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 4,212,485\n",
      "Trainable params: 4,212,293\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = Adam(lr=0.0005,clipvalue=1.0) #write your optimizer\n",
    "model_2.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalation = None  #Set ablation to 100 for ablation runs.\n",
    "train_generator = generator(train_path, train_doc, batch_size, abalation=abalation)\n",
    "val_generator = generator(val_path, val_doc, batch_size, abalation=abalation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=2, min_lr=0.00001)  # write the REducelronplateau code here\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (abalation%batch_size) == 0:\n",
    "#     steps_per_epoch = int(abalation/batch_size)\n",
    "# else:\n",
    "#     steps_per_epoch = (abalation//batch_size) + 1\n",
    "\n",
    "# if (abalation%batch_size) == 0:\n",
    "#     validation_steps = int(abalation/batch_size)\n",
    "# else:\n",
    "#     validation_steps = (abalation//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size =Source path =  Project_data/train ; batch size = 50\n",
      " 50\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  app.launch_new_instance()\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14 [========================>.....] - ETA: 13s - loss: 10.2675 - categorical_accuracy: 0.2083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 86s 6s/step - loss: 10.1853 - categorical_accuracy: 0.2055 - val_loss: 11.2682 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-12-1909_55_34.279723/model-00001-10.24915-0.20814-11.26821-0.27000.h5\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 6.2768 - categorical_accuracy: 0.4545 - val_loss: 8.8290 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-12-1909_55_34.279723/model-00002-6.59614-0.42578-8.82896-0.22000.h5\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 59s 4s/step - loss: 6.7841 - categorical_accuracy: 0.3348 - val_loss: 8.7447 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-12-1909_55_34.279723/model-00003-7.15431-0.33956-8.74475-0.23000.h5\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 27s 2s/step - loss: 3.0359 - categorical_accuracy: 0.5934 - val_loss: 5.4500 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-12-1909_55_34.279723/model-00004-3.76271-0.51212-5.44999-0.32000.h5\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 51s 4s/step - loss: 2.7576 - categorical_accuracy: 0.2904 - val_loss: 2.0836 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-12-1909_55_34.279723/model-00005-2.86783-0.33010-2.08364-0.38000.h5\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 35s 3s/step - loss: 1.4369 - categorical_accuracy: 0.3750 - val_loss: 3.0146 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-12-1909_55_34.279723/model-00006-1.56196-0.36881-3.01460-0.31000.h5\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 41s 3s/step - loss: 1.3965 - categorical_accuracy: 0.3553 - val_loss: 3.0557 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-12-1909_55_34.279723/model-00007-1.47795-0.35147-3.05569-0.32000.h5\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 43s 3s/step - loss: 1.2753 - categorical_accuracy: 0.4592 - val_loss: 2.1605 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-12-1909_55_34.279723/model-00008-1.37020-0.42050-2.16047-0.38000.h5\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 33s 2s/step - loss: 1.1815 - categorical_accuracy: 0.5080 - val_loss: 2.0716 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-12-1909_55_34.279723/model-00009-1.29086-0.49046-2.07157-0.40000.h5\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 54s 4s/step - loss: 1.3382 - categorical_accuracy: 0.4858 - val_loss: 1.6414 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-12-1909_55_34.279723/model-00010-1.43604-0.44928-1.64142-0.51000.h5\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 22s 2s/step - loss: 1.2005 - categorical_accuracy: 0.4924 - val_loss: 1.6747 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-12-1909_55_34.279723/model-00011-1.26918-0.47099-1.67469-0.54000.h5\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 65s 5s/step - loss: 1.3723 - categorical_accuracy: 0.4408 - val_loss: 1.7386 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-12-1909_55_34.279723/model-00012-1.40022-0.42173-1.73860-0.53000.h5\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 12s 827ms/step - loss: 1.1067 - categorical_accuracy: 0.4869 - val_loss: 1.6878 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-12-1909_55_34.279723/model-00013-1.15319-0.47945-1.68782-0.52000.h5\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 72s 5s/step - loss: 1.4006 - categorical_accuracy: 0.4138 - val_loss: 1.6431 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-12-1909_55_34.279723/model-00014-1.41844-0.41931-1.64310-0.53000.h5\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.9756 - categorical_accuracy: 0.5431 - val_loss: 1.4953 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-12-1909_55_34.279723/model-00015-1.10335-0.53125-1.49526-0.47000.h5\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 61s 4s/step - loss: 1.3481 - categorical_accuracy: 0.4276 - val_loss: 1.4414 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-12-1909_55_34.279723/model-00016-1.32619-0.46180-1.44138-0.52000.h5\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 27s 2s/step - loss: 1.2286 - categorical_accuracy: 0.4422 - val_loss: 1.6552 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-12-1909_55_34.279723/model-00017-1.22836-0.47576-1.65520-0.58000.h5\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 51s 4s/step - loss: 1.2804 - categorical_accuracy: 0.4416 - val_loss: 1.6383 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-12-1909_55_34.279723/model-00018-1.30930-0.46019-1.63833-0.59000.h5\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 34s 2s/step - loss: 1.1469 - categorical_accuracy: 0.5052 - val_loss: 1.7904 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-12-1909_55_34.279723/model-00019-1.14872-0.51485-1.79042-0.52000.h5\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 43s 3s/step - loss: 1.2183 - categorical_accuracy: 0.4561 - val_loss: 1.5911 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-12-1909_55_34.279723/model-00020-1.23717-0.46485-1.59109-0.53000.h5\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 44s 3s/step - loss: 1.1858 - categorical_accuracy: 0.5638 - val_loss: 1.6465 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-12-1909_55_34.279723/model-00021-1.21287-0.53138-1.64653-0.54000.h5\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 33s 2s/step - loss: 1.1361 - categorical_accuracy: 0.5300 - val_loss: 1.5196 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-12-1909_55_34.279723/model-00022-1.17942-0.48229-1.51958-0.57000.h5\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 55s 4s/step - loss: 1.1384 - categorical_accuracy: 0.5391 - val_loss: 1.5133 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-12-1909_55_34.279723/model-00023-1.16646-0.51087-1.51332-0.58000.h5\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 22s 2s/step - loss: 1.0046 - categorical_accuracy: 0.5763 - val_loss: 1.5916 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-12-1909_55_34.279723/model-00024-1.00975-0.56314-1.59159-0.58000.h5\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 1.0718 - categorical_accuracy: 0.5431 - val_loss: 1.5774 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-12-1909_55_34.279723/model-00025-1.09339-0.53514-1.57745-0.60000.h5\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 12s 840ms/step - loss: 1.0440 - categorical_accuracy: 0.4701 - val_loss: 1.4520 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-12-1909_55_34.279723/model-00026-1.04530-0.47489-1.45201-0.65000.h5\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 71s 5s/step - loss: 1.0621 - categorical_accuracy: 0.5352 - val_loss: 1.4008 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-12-1909_55_34.279723/model-00027-1.05706-0.54299-1.40082-0.63000.h5\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.9904 - categorical_accuracy: 0.4940 - val_loss: 1.4561 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-12-1909_55_34.279723/model-00028-1.03685-0.50391-1.45610-0.56000.h5\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 62s 4s/step - loss: 1.0734 - categorical_accuracy: 0.4867 - val_loss: 1.4211 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-12-1909_55_34.279723/model-00029-1.09084-0.51783-1.42107-0.56000.h5\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0853 - categorical_accuracy: 0.4117 - val_loss: 1.4149 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-12-1909_55_34.279723/model-00030-1.06982-0.46061-1.41491-0.56000.h5\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 52s 4s/step - loss: 1.0972 - categorical_accuracy: 0.4773 - val_loss: 1.3998 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00031: saving model to model_init_2020-12-1909_55_34.279723/model-00031-1.06649-0.53786-1.39984-0.58000.h5\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 35s 3s/step - loss: 1.1019 - categorical_accuracy: 0.4896 - val_loss: 1.3861 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00032: saving model to model_init_2020-12-1909_55_34.279723/model-00032-1.02841-0.56436-1.38608-0.57000.h5\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 42s 3s/step - loss: 1.0523 - categorical_accuracy: 0.4784 - val_loss: 1.3812 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00033: saving model to model_init_2020-12-1909_55_34.279723/model-00033-1.06575-0.49887-1.38116-0.55000.h5\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 45s 3s/step - loss: 0.9943 - categorical_accuracy: 0.5532 - val_loss: 1.3728 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00034: saving model to model_init_2020-12-1909_55_34.279723/model-00034-0.99921-0.56485-1.37277-0.56000.h5\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.9741 - categorical_accuracy: 0.6278 - val_loss: 1.3594 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00035: saving model to model_init_2020-12-1909_55_34.279723/model-00035-1.03684-0.58311-1.35937-0.55000.h5\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 54s 4s/step - loss: 0.9188 - categorical_accuracy: 0.6538 - val_loss: 1.3521 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00036: saving model to model_init_2020-12-1909_55_34.279723/model-00036-0.96020-0.61594-1.35208-0.59000.h5\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.9430 - categorical_accuracy: 0.4873 - val_loss: 1.3428 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00037: saving model to model_init_2020-12-1909_55_34.279723/model-00037-1.03885-0.48464-1.34285-0.59000.h5\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 63s 5s/step - loss: 0.9915 - categorical_accuracy: 0.5581 - val_loss: 1.3226 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00038: saving model to model_init_2020-12-1909_55_34.279723/model-00038-1.00769-0.56869-1.32258-0.59000.h5\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 12s 837ms/step - loss: 0.7345 - categorical_accuracy: 0.6505 - val_loss: 1.2968 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00039: saving model to model_init_2020-12-1909_55_34.279723/model-00039-0.76876-0.63927-1.29683-0.58000.h5\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 70s 5s/step - loss: 0.9455 - categorical_accuracy: 0.5524 - val_loss: 1.2761 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00040: saving model to model_init_2020-12-1909_55_34.279723/model-00040-0.96358-0.56109-1.27609-0.58000.h5\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.7946 - categorical_accuracy: 0.6253 - val_loss: 1.2690 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00041: saving model to model_init_2020-12-1909_55_34.279723/model-00041-0.82252-0.62109-1.26904-0.55000.h5\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 61s 4s/step - loss: 0.9354 - categorical_accuracy: 0.5670 - val_loss: 1.2771 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00042: saving model to model_init_2020-12-1909_55_34.279723/model-00042-1.00217-0.55857-1.27713-0.53000.h5\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.6611 - categorical_accuracy: 0.7471 - val_loss: 1.2803 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00043: saving model to model_init_2020-12-1909_55_34.279723/model-00043-0.76759-0.70303-1.28026-0.56000.h5\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 52s 4s/step - loss: 0.9236 - categorical_accuracy: 0.5258 - val_loss: 1.2676 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00044: saving model to model_init_2020-12-1909_55_34.279723/model-00044-0.95025-0.54175-1.26757-0.57000.h5\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 35s 2s/step - loss: 0.8793 - categorical_accuracy: 0.5753 - val_loss: 1.2547 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00045: saving model to model_init_2020-12-1909_55_34.279723/model-00045-0.92712-0.57426-1.25472-0.56000.h5\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.8958 - categorical_accuracy: 0.6003 - val_loss: 1.2407 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00046: saving model to model_init_2020-12-1909_55_34.279723/model-00046-0.88563-0.62132-1.24073-0.57000.h5\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 44s 3s/step - loss: 0.8323 - categorical_accuracy: 0.6055 - val_loss: 1.2453 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00047: saving model to model_init_2020-12-1909_55_34.279723/model-00047-0.85137-0.60669-1.24531-0.55000.h5\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 34s 2s/step - loss: 1.0382 - categorical_accuracy: 0.5739 - val_loss: 1.2356 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00048: saving model to model_init_2020-12-1909_55_34.279723/model-00048-1.04095-0.54768-1.23559-0.56000.h5\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 55s 4s/step - loss: 0.8644 - categorical_accuracy: 0.6180 - val_loss: 1.2315 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00049: saving model to model_init_2020-12-1909_55_34.279723/model-00049-0.90831-0.57609-1.23148-0.53000.h5\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.9545 - categorical_accuracy: 0.5105 - val_loss: 1.2155 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00050: saving model to model_init_2020-12-1909_55_34.279723/model-00050-0.89829-0.57679-1.21549-0.55000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff44fe05a90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 has a worse accuracy than Model 1, with validation loss ~1.25 and validation accuracy ~0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will build Model 3 with an extra CNN layer and no Dropouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', padding = 'same', input_shape=input_shape))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling3D(pool_size=(2, 3, 3)))\n",
    "\n",
    "model_3.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling3D(pool_size=(2, 3, 3)))\n",
    "\n",
    "model_3.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_5 (Conv3D)            (None, 15, 120, 120, 32)  2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 120, 120, 32)  128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 7, 40, 40, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 7, 40, 40, 64)     55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 40, 40, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 3, 13, 13, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 3, 13, 13, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 3, 13, 13, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               1179904   \n",
      "=================================================================\n",
      "Total params: 1,460,096\n",
      "Trainable params: 1,459,648\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = RMSprop(lr=0.0005,clipvalue=1.0) #write your optimizer\n",
    "model_3.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalation = None\n",
    "train_generator = generator(train_path, train_doc, batch_size, abalation=abalation)\n",
    "val_generator = generator(val_path, val_doc, batch_size, abalation=abalation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=2, min_lr=0.00001)  # write the REducelronplateau code here\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (abalation%batch_size) == 0:\n",
    "#     steps_per_epoch = int(abalation/batch_size)\n",
    "# else:\n",
    "#     steps_per_epoch = (abalation//batch_size) + 1\n",
    "\n",
    "# if (abalation%batch_size) == 0:\n",
    "#     validation_steps = int(abalation/batch_size)\n",
    "# else:\n",
    "#     validation_steps = (abalation//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 50\n",
      "Source path =  Project_data/train ; batch size =Epoch 1/50\n",
      " 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  app.launch_new_instance()\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14 [========================>.....] - ETA: 13s - loss: 9.8173 - categorical_accuracy: 0.3100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 87s 6s/step - loss: 9.8713 - categorical_accuracy: 0.3001 - val_loss: 10.3103 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-12-1910_45_29.721063/model-00001-9.86849-0.30769-10.31030-0.35000.h5\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 16s 1s/step - loss: 12.7565 - categorical_accuracy: 0.1819 - val_loss: 10.6264 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-12-1910_45_29.721063/model-00002-11.92675-0.22266-10.62641-0.33000.h5\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 61s 4s/step - loss: 6.7557 - categorical_accuracy: 0.3856 - val_loss: 8.2119 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-12-1910_45_29.721063/model-00003-7.36164-0.37691-8.21189-0.25000.h5\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.7726 - categorical_accuracy: 0.8091 - val_loss: 4.1941 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-12-1910_45_29.721063/model-00004-1.40159-0.66061-4.19411-0.40000.h5\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 51s 4s/step - loss: 1.1357 - categorical_accuracy: 0.6286 - val_loss: 1.6754 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-12-1910_45_29.721063/model-00005-1.35093-0.58252-1.67540-0.56000.h5\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 37s 3s/step - loss: 0.6743 - categorical_accuracy: 0.7872 - val_loss: 2.0500 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-12-1910_45_29.721063/model-00006-1.10996-0.64851-2.05001-0.51000.h5\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.5654 - categorical_accuracy: 0.7402 - val_loss: 6.1082 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-12-1910_45_29.721063/model-00007-0.69385-0.70748-6.10817-0.29000.h5\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 44s 3s/step - loss: 0.3064 - categorical_accuracy: 0.8645 - val_loss: 1.3618 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-12-1910_45_29.721063/model-00008-0.43473-0.80753-1.36183-0.73000.h5\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.1998 - categorical_accuracy: 0.8855 - val_loss: 1.1875 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-12-1910_45_29.721063/model-00009-0.26534-0.86921-1.18747-0.71000.h5\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 55s 4s/step - loss: 0.2521 - categorical_accuracy: 0.9026 - val_loss: 1.4607 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-12-1910_45_29.721063/model-00010-0.31378-0.87862-1.46074-0.69000.h5\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.0853 - categorical_accuracy: 0.9476 - val_loss: 1.8260 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-12-1910_45_29.721063/model-00011-0.16868-0.93515-1.82604-0.66000.h5\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 64s 5s/step - loss: 0.1185 - categorical_accuracy: 0.9683 - val_loss: 1.1095 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-12-1910_45_29.721063/model-00012-0.13142-0.96486-1.10954-0.72000.h5\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 11s 785ms/step - loss: 0.0425 - categorical_accuracy: 0.9332 - val_loss: 0.9461 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-12-1910_45_29.721063/model-00013-0.05945-0.94064-0.94610-0.67000.h5\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 74s 5s/step - loss: 0.0456 - categorical_accuracy: 0.9728 - val_loss: 0.9693 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-12-1910_45_29.721063/model-00014-0.04695-0.98341-0.96932-0.76000.h5\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.0042 - categorical_accuracy: 0.9838 - val_loss: 1.3632 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-12-1910_45_29.721063/model-00015-0.00906-0.98828-1.36324-0.72000.h5\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 0.0138 - categorical_accuracy: 0.9619 - val_loss: 1.4748 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-12-1910_45_29.721063/model-00016-0.01088-0.98642-1.47476-0.69000.h5\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.0141 - categorical_accuracy: 0.9969 - val_loss: 1.2678 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-12-1910_45_29.721063/model-00017-0.02761-0.99394-1.26776-0.72000.h5\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 52s 4s/step - loss: 0.0133 - categorical_accuracy: 0.9655 - val_loss: 1.3639 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-12-1910_45_29.721063/model-00018-0.01701-0.98447-1.36389-0.73000.h5\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 1.0971 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-12-1910_45_29.721063/model-00019-0.00213-1.00000-1.09713-0.79000.h5\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0012 - categorical_accuracy: 0.9683 - val_loss: 0.9785 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-12-1910_45_29.721063/model-00020-0.00171-0.98639-0.97852-0.77000.h5\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 45s 3s/step - loss: 3.7597e-04 - categorical_accuracy: 1.0000 - val_loss: 0.9205 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-12-1910_45_29.721063/model-00021-0.00051-1.00000-0.92053-0.80000.h5\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 33s 2s/step - loss: 4.7340e-04 - categorical_accuracy: 0.9681 - val_loss: 0.8848 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-12-1910_45_29.721063/model-00022-0.00073-0.98365-0.88482-0.77000.h5\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 55s 4s/step - loss: 2.2514e-04 - categorical_accuracy: 1.0000 - val_loss: 0.9372 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-12-1910_45_29.721063/model-00023-0.00028-1.00000-0.93723-0.79000.h5\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 22s 2s/step - loss: 6.4843e-04 - categorical_accuracy: 0.9625 - val_loss: 1.2276 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-12-1910_45_29.721063/model-00024-0.00137-0.97611-1.22756-0.74000.h5\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 64s 5s/step - loss: 4.8049e-04 - categorical_accuracy: 1.0000 - val_loss: 0.9105 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-12-1910_45_29.721063/model-00025-0.00053-1.00000-0.91050-0.79000.h5\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 11s 783ms/step - loss: 2.9270e-05 - categorical_accuracy: 0.9076 - val_loss: 0.8541 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-12-1910_45_29.721063/model-00026-0.00004-0.92237-0.85410-0.80000.h5\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 71s 5s/step - loss: 1.1670e-04 - categorical_accuracy: 0.9791 - val_loss: 1.0007 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-12-1910_45_29.721063/model-00027-0.00012-0.99397-1.00068-0.78000.h5\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 2.2659e-05 - categorical_accuracy: 0.9838 - val_loss: 0.9298 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-12-1910_45_29.721063/model-00028-0.00005-0.98828-0.92982-0.78000.h5\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 61s 4s/step - loss: 1.1161e-04 - categorical_accuracy: 0.9686 - val_loss: 1.3317 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-12-1910_45_29.721063/model-00029-0.00008-0.98981-1.33174-0.73000.h5\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 27s 2s/step - loss: 1.7645e-05 - categorical_accuracy: 1.0000 - val_loss: 1.1222 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-12-1910_45_29.721063/model-00030-0.00003-1.00000-1.12217-0.76000.h5\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 51s 4s/step - loss: 2.3496e-05 - categorical_accuracy: 0.9685 - val_loss: 0.9480 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00031: saving model to model_init_2020-12-1910_45_29.721063/model-00031-0.00003-0.98835-0.94796-0.79000.h5\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 35s 3s/step - loss: 8.7002e-06 - categorical_accuracy: 1.0000 - val_loss: 0.9718 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00032: saving model to model_init_2020-12-1910_45_29.721063/model-00032-0.00001-1.00000-0.97180-0.79000.h5\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 41s 3s/step - loss: 1.6370e-05 - categorical_accuracy: 0.9683 - val_loss: 0.8556 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00033: saving model to model_init_2020-12-1910_45_29.721063/model-00033-0.00002-0.98639-0.85562-0.80000.h5\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 44s 3s/step - loss: 1.1414e-05 - categorical_accuracy: 1.0000 - val_loss: 0.9299 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00034: saving model to model_init_2020-12-1910_45_29.721063/model-00034-0.00002-1.00000-0.92992-0.81000.h5\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 33s 2s/step - loss: 1.6618e-05 - categorical_accuracy: 0.9681 - val_loss: 1.1257 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00035: saving model to model_init_2020-12-1910_45_29.721063/model-00035-0.00002-0.98365-1.12572-0.77000.h5\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 54s 4s/step - loss: 5.2840e-06 - categorical_accuracy: 1.0000 - val_loss: 0.9498 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00036: saving model to model_init_2020-12-1910_45_29.721063/model-00036-0.00001-1.00000-0.94984-0.81000.h5\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 22s 2s/step - loss: 5.6793e-06 - categorical_accuracy: 0.9679 - val_loss: 0.9361 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00037: saving model to model_init_2020-12-1910_45_29.721063/model-00037-0.00001-0.97952-0.93611-0.80000.h5\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 5.7423e-06 - categorical_accuracy: 1.0000 - val_loss: 0.9058 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00038: saving model to model_init_2020-12-1910_45_29.721063/model-00038-0.00001-1.00000-0.90581-0.80000.h5\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 12s 833ms/step - loss: 1.0048e-04 - categorical_accuracy: 0.9457 - val_loss: 0.9065 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00039: saving model to model_init_2020-12-1910_45_29.721063/model-00039-0.00009-0.95434-0.90650-0.80000.h5\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 69s 5s/step - loss: 3.4717e-04 - categorical_accuracy: 0.9843 - val_loss: 0.9735 - val_categorical_accuracy: 0.8200\n",
      "\n",
      "Epoch 00040: saving model to model_init_2020-12-1910_45_29.721063/model-00040-0.00010-0.99548-0.97350-0.82000.h5\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 16s 1s/step - loss: 1.3030e-05 - categorical_accuracy: 0.9838 - val_loss: 0.9297 - val_categorical_accuracy: 0.8200\n",
      "\n",
      "Epoch 00041: saving model to model_init_2020-12-1910_45_29.721063/model-00041-0.00001-0.98828-0.92974-0.82000.h5\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 61s 4s/step - loss: 1.1910e-04 - categorical_accuracy: 0.9686 - val_loss: 0.9165 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00042: saving model to model_init_2020-12-1910_45_29.721063/model-00042-0.00004-0.98981-0.91645-0.83000.h5\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 26s 2s/step - loss: 4.3725e-06 - categorical_accuracy: 1.0000 - val_loss: 0.9228 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00043: saving model to model_init_2020-12-1910_45_29.721063/model-00043-0.00000-1.00000-0.92276-0.83000.h5\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 51s 4s/step - loss: 4.7065e-06 - categorical_accuracy: 0.9685 - val_loss: 0.9144 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00044: saving model to model_init_2020-12-1910_45_29.721063/model-00044-0.00000-0.98835-0.91438-0.83000.h5\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 36s 3s/step - loss: 2.4829e-06 - categorical_accuracy: 1.0000 - val_loss: 0.9110 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00045: saving model to model_init_2020-12-1910_45_29.721063/model-00045-0.00000-1.00000-0.91097-0.81000.h5\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 41s 3s/step - loss: 5.3708e-06 - categorical_accuracy: 0.9683 - val_loss: 0.9220 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00046: saving model to model_init_2020-12-1910_45_29.721063/model-00046-0.00000-0.98639-0.92202-0.80000.h5\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 45s 3s/step - loss: 2.7311e-06 - categorical_accuracy: 1.0000 - val_loss: 0.9184 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00047: saving model to model_init_2020-12-1910_45_29.721063/model-00047-0.00000-1.00000-0.91845-0.80000.h5\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 1.9241e-06 - categorical_accuracy: 0.9628 - val_loss: 0.9262 - val_categorical_accuracy: 0.8200\n",
      "\n",
      "Epoch 00048: saving model to model_init_2020-12-1910_45_29.721063/model-00048-0.00000-0.98093-0.92618-0.82000.h5\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 54s 4s/step - loss: 3.6670e-06 - categorical_accuracy: 1.0000 - val_loss: 0.9142 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00049: saving model to model_init_2020-12-1910_45_29.721063/model-00049-0.00000-1.00000-0.91415-0.80000.h5\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 22s 2s/step - loss: 8.0957e-06 - categorical_accuracy: 0.9572 - val_loss: 0.9199 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00050: saving model to model_init_2020-12-1910_45_29.721063/model-00050-0.00001-0.97270-0.91986-0.81000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff452356208>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 has an validation loss ~0.9 and validation categorical accuracy of ~0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will add two more layers of CNN for model 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', padding = 'same', input_shape=input_shape))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_4.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_4.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_4.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "model_4.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(512, activation='relu'))\n",
    "model_4.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_6 (Conv3D)            (None, 15, 120, 120, 32)  2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 15, 120, 120, 32)  128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 7, 60, 60, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 7, 60, 60, 64)     55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 7, 60, 60, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 3, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 3, 30, 30, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 3, 30, 30, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 1, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 1, 15, 15, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1, 15, 15, 256)    1024      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 1, 7, 7, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 1, 7, 7, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1, 7, 7, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 1, 3, 3, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 4,119,685\n",
      "Trainable params: 4,118,213\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = RMSprop(lr=0.0008,clipvalue=1.0) #write your optimizer\n",
    "model_4.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalation = None\n",
    "train_generator = generator(train_path, train_doc, batch_size, abalation=abalation)\n",
    "val_generator = generator(val_path, val_doc, batch_size, abalation=abalation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=2, min_lr=0.00001)  # write the REducelronplateau code here\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (abalation%batch_size) == 0:\n",
    "#     steps_per_epoch = int(abalation/batch_size)\n",
    "# else:\n",
    "#     steps_per_epoch = (abalation//batch_size) + 1\n",
    "\n",
    "# if (abalation%batch_size) == 0:\n",
    "#     validation_steps = int(abalation/batch_size)\n",
    "# else:\n",
    "#     validation_steps = (abalation//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 50\n",
      "Source path =  Project_data/train ; batch size = 50\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  app.launch_new_instance()\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14 [========================>.....] - ETA: 13s - loss: 12.1861 - categorical_accuracy: 0.1767"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 89s 6s/step - loss: 12.1290 - categorical_accuracy: 0.1739 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-12-1911_20_14.278737/model-00001-12.24373-0.17496-13.53920-0.16000.h5\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 19s 1s/step - loss: 12.2427 - categorical_accuracy: 0.2243 - val_loss: 13.5392 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-12-1911_20_14.278737/model-00002-12.46634-0.21484-13.53920-0.16000.h5\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 63s 4s/step - loss: 12.6050 - categorical_accuracy: 0.1598 - val_loss: 12.5721 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-12-1911_20_14.278737/model-00003-12.96692-0.16978-12.57211-0.22000.h5\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 5.5239 - categorical_accuracy: 0.4720 - val_loss: 5.5745 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-12-1911_20_14.278737/model-00004-6.05626-0.38485-5.57454-0.23000.h5\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 53s 4s/step - loss: 2.2904 - categorical_accuracy: 0.4347 - val_loss: 2.6936 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-12-1911_20_14.278737/model-00005-2.82710-0.35534-2.69365-0.27000.h5\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 36s 3s/step - loss: 1.3536 - categorical_accuracy: 0.6988 - val_loss: 2.4428 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-12-1911_20_14.278737/model-00006-2.22323-0.50248-2.44275-0.34000.h5\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 43s 3s/step - loss: 1.2876 - categorical_accuracy: 0.5299 - val_loss: 3.3220 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-12-1911_20_14.278737/model-00007-1.52461-0.45578-3.32201-0.39000.h5\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.9792 - categorical_accuracy: 0.6583 - val_loss: 1.3893 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-12-1911_20_14.278737/model-00008-1.37652-0.51464-1.38926-0.50000.h5\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.6196 - categorical_accuracy: 0.7348 - val_loss: 1.8558 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-12-1911_20_14.278737/model-00009-0.98115-0.59128-1.85579-0.43000.h5\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 53s 4s/step - loss: 0.9937 - categorical_accuracy: 0.6336 - val_loss: 4.1028 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-12-1911_20_14.278737/model-00010-1.23657-0.54348-4.10277-0.41000.h5\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.4581 - categorical_accuracy: 0.8220 - val_loss: 1.9530 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-12-1911_20_14.278737/model-00011-0.73278-0.72696-1.95298-0.52000.h5\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 61s 4s/step - loss: 0.8379 - categorical_accuracy: 0.7005 - val_loss: 1.9270 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-12-1911_20_14.278737/model-00012-0.92830-0.66773-1.92700-0.44000.h5\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 14s 990ms/step - loss: 0.2622 - categorical_accuracy: 0.8662 - val_loss: 1.5659 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-12-1911_20_14.278737/model-00013-0.36569-0.81735-1.56591-0.48000.h5\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 68s 5s/step - loss: 0.6630 - categorical_accuracy: 0.7340 - val_loss: 1.8393 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-12-1911_20_14.278737/model-00014-0.65336-0.74811-1.83934-0.53000.h5\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.0916 - categorical_accuracy: 0.9567 - val_loss: 2.7863 - val_categorical_accuracy: 0.4100\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-12-1911_20_14.278737/model-00015-0.17668-0.92188-2.78628-0.41000.h5\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 60s 4s/step - loss: 0.3681 - categorical_accuracy: 0.8270 - val_loss: 1.3907 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-12-1911_20_14.278737/model-00016-0.39839-0.83701-1.39075-0.55000.h5\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.1019 - categorical_accuracy: 0.9616 - val_loss: 1.1499 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-12-1911_20_14.278737/model-00017-0.19567-0.92424-1.14990-0.64000.h5\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.5708 - categorical_accuracy: 0.8834 - val_loss: 1.7882 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-12-1911_20_14.278737/model-00018-0.33003-0.91068-1.78819-0.43000.h5\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 36s 3s/step - loss: 0.7523 - categorical_accuracy: 0.9367 - val_loss: 1.4518 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-12-1911_20_14.278737/model-00019-0.43292-0.94554-1.45176-0.53000.h5\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 41s 3s/step - loss: 0.0943 - categorical_accuracy: 0.9461 - val_loss: 1.8393 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-12-1911_20_14.278737/model-00020-0.13694-0.95238-1.83926-0.52000.h5\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0338 - categorical_accuracy: 0.9926 - val_loss: 1.3166 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-12-1911_20_14.278737/model-00021-0.04750-0.98954-1.31663-0.53000.h5\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.0541 - categorical_accuracy: 0.9568 - val_loss: 1.4214 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-12-1911_20_14.278737/model-00022-0.08242-0.97003-1.42144-0.52000.h5\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 52s 4s/step - loss: 0.0508 - categorical_accuracy: 0.9942 - val_loss: 0.9270 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-12-1911_20_14.278737/model-00023-0.06298-0.99275-0.92699-0.70000.h5\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.0081 - categorical_accuracy: 0.9663 - val_loss: 1.0619 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-12-1911_20_14.278737/model-00024-0.01454-0.97611-1.06192-0.65000.h5\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 61s 4s/step - loss: 0.0360 - categorical_accuracy: 0.9971 - val_loss: 0.7972 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-12-1911_20_14.278737/model-00025-0.03992-0.99681-0.79720-0.71000.h5\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 13s 944ms/step - loss: 0.0056 - categorical_accuracy: 0.9674 - val_loss: 1.0253 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-12-1911_20_14.278737/model-00026-0.00666-0.97260-1.02529-0.67000.h5\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 68s 5s/step - loss: 0.0336 - categorical_accuracy: 0.9743 - val_loss: 0.9608 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-12-1911_20_14.278737/model-00027-0.03415-0.98492-0.96082-0.73000.h5\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.9608 - categorical_accuracy: 0.9230 - val_loss: 0.7817 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-12-1911_20_14.278737/model-00028-0.70412-0.94141-0.78174-0.74000.h5\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 60s 4s/step - loss: 0.0299 - categorical_accuracy: 0.9671 - val_loss: 0.7320 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-12-1911_20_14.278737/model-00029-0.03235-0.98812-0.73202-0.77000.h5\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.0259 - categorical_accuracy: 0.9985 - val_loss: 0.6463 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-12-1911_20_14.278737/model-00030-0.05055-0.99697-0.64626-0.78000.h5\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 52s 4s/step - loss: 0.0023 - categorical_accuracy: 0.9685 - val_loss: 0.9042 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00031: saving model to model_init_2020-12-1911_20_14.278737/model-00031-0.00266-0.98835-0.90422-0.75000.h5\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 35s 3s/step - loss: 6.8353e-04 - categorical_accuracy: 1.0000 - val_loss: 0.7045 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00032: saving model to model_init_2020-12-1911_20_14.278737/model-00032-0.00106-1.00000-0.70449-0.77000.h5\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.0246 - categorical_accuracy: 0.9668 - val_loss: 0.8199 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00033: saving model to model_init_2020-12-1911_20_14.278737/model-00033-0.03741-0.98413-0.81993-0.77000.h5\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 45s 3s/step - loss: 0.0029 - categorical_accuracy: 0.9985 - val_loss: 0.8851 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00034: saving model to model_init_2020-12-1911_20_14.278737/model-00034-0.00407-0.99791-0.88514-0.78000.h5\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.0387 - categorical_accuracy: 0.9560 - val_loss: 0.8189 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00035: saving model to model_init_2020-12-1911_20_14.278737/model-00035-0.05175-0.97548-0.81891-0.78000.h5\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 52s 4s/step - loss: 0.0241 - categorical_accuracy: 0.9985 - val_loss: 0.7970 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00036: saving model to model_init_2020-12-1911_20_14.278737/model-00036-0.02999-0.99819-0.79703-0.77000.h5\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.0027 - categorical_accuracy: 0.9679 - val_loss: 0.7113 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00037: saving model to model_init_2020-12-1911_20_14.278737/model-00037-0.00316-0.97952-0.71134-0.80000.h5\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 62s 4s/step - loss: 0.0237 - categorical_accuracy: 0.9986 - val_loss: 0.7235 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00038: saving model to model_init_2020-12-1911_20_14.278737/model-00038-0.02626-0.99840-0.72354-0.78000.h5\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 13s 922ms/step - loss: 3.9193e-04 - categorical_accuracy: 0.9674 - val_loss: 0.7429 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00039: saving model to model_init_2020-12-1911_20_14.278737/model-00039-0.00047-0.97260-0.74292-0.79000.h5\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 68s 5s/step - loss: 0.0236 - categorical_accuracy: 0.9829 - val_loss: 0.7575 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00040: saving model to model_init_2020-12-1911_20_14.278737/model-00040-0.02476-0.99397-0.75754-0.79000.h5\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 19s 1s/step - loss: 8.7243e-05 - categorical_accuracy: 0.9838 - val_loss: 0.7734 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00041: saving model to model_init_2020-12-1911_20_14.278737/model-00041-0.00011-0.98828-0.77335-0.79000.h5\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 59s 4s/step - loss: 0.0236 - categorical_accuracy: 0.9671 - val_loss: 0.8463 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00042: saving model to model_init_2020-12-1911_20_14.278737/model-00042-0.02760-0.98812-0.84632-0.77000.h5\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.0249 - categorical_accuracy: 0.9985 - val_loss: 0.8377 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00043: saving model to model_init_2020-12-1911_20_14.278737/model-00043-0.04901-0.99697-0.83771-0.78000.h5\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 52s 4s/step - loss: 1.6172e-04 - categorical_accuracy: 0.9685 - val_loss: 0.8930 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00044: saving model to model_init_2020-12-1911_20_14.278737/model-00044-0.00019-0.98835-0.89302-0.78000.h5\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 36s 3s/step - loss: 2.2360e-04 - categorical_accuracy: 1.0000 - val_loss: 0.9039 - val_categorical_accuracy: 0.7800\n",
      "\n",
      "Epoch 00045: saving model to model_init_2020-12-1911_20_14.278737/model-00045-0.00035-1.00000-0.90389-0.78000.h5\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 41s 3s/step - loss: 0.0241 - categorical_accuracy: 0.9668 - val_loss: 0.7881 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00046: saving model to model_init_2020-12-1911_20_14.278737/model-00046-0.03674-0.98413-0.78809-0.81000.h5\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 44s 3s/step - loss: 0.0239 - categorical_accuracy: 0.9985 - val_loss: 0.8082 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00047: saving model to model_init_2020-12-1911_20_14.278737/model-00047-0.03386-0.99791-0.80818-0.83000.h5\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 34s 2s/step - loss: 1.3169e-04 - categorical_accuracy: 0.9681 - val_loss: 0.8009 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00048: saving model to model_init_2020-12-1911_20_14.278737/model-00048-0.00016-0.98365-0.80090-0.80000.h5\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 52s 4s/step - loss: 0.0236 - categorical_accuracy: 0.9985 - val_loss: 0.8268 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00049: saving model to model_init_2020-12-1911_20_14.278737/model-00049-0.02934-0.99819-0.82675-0.81000.h5\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 25s 2s/step - loss: 1.2262e-04 - categorical_accuracy: 0.9679 - val_loss: 0.8127 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00050: saving model to model_init_2020-12-1911_20_14.278737/model-00050-0.00011-0.97952-0.81266-0.81000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff452356da0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 has a validation loss ~0.8 and validation catgorical accuracy of ~0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Model 5 we will add dropout in the layers after flatten layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', padding = 'same', input_shape=input_shape))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_5.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_5.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "model_5.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_5.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_5.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "model_5.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_5.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_5.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "model_5.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "model_5.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_5.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "model_5.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(512, activation='relu'))\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_6 (Conv3D)            (None, 15, 120, 120, 32)  2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 15, 120, 120, 32)  128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 7, 60, 60, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 7, 60, 60, 64)     55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 7, 60, 60, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 3, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 3, 30, 30, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 3, 30, 30, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 1, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 1, 15, 15, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1, 15, 15, 256)    1024      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 1, 7, 7, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 1, 7, 7, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1, 7, 7, 256)      1024      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 1, 3, 3, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 4,119,685\n",
      "Trainable params: 4,118,213\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = RMSprop(lr=0.0005,clipvalue=1.0) #write your optimizer\n",
    "model_5.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalation = None\n",
    "train_generator = generator(train_path, train_doc, batch_size, abalation=abalation)\n",
    "val_generator = generator(val_path, val_doc, batch_size, abalation=abalation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=2, min_lr=0.00001)  # write the REducelronplateau code here\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (abalation%batch_size) == 0:\n",
    "#     steps_per_epoch = int(abalation/batch_size)\n",
    "# else:\n",
    "#     steps_per_epoch = (abalation//batch_size) + 1\n",
    "\n",
    "# if (abalation%batch_size) == 0:\n",
    "#     validation_steps = int(abalation/batch_size)\n",
    "# else:\n",
    "#     validation_steps = (abalation//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  app.launch_new_instance()\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 10s 743ms/step - loss: 0.0262 - categorical_accuracy: 0.8881 - val_loss: 0.7159 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-12-2006_50_15.615578/model-00001-0.03442-0.89954-0.71591-0.81000.h5\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 46s 3s/step - loss: 0.1239 - categorical_accuracy: 0.9278 - val_loss: 0.8857 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-12-2006_50_15.615578/model-00002-0.13319-0.94089-0.88572-0.72000.h5\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.0683 - categorical_accuracy: 0.9761 - val_loss: 0.8587 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-12-2006_50_15.615578/model-00003-0.08466-0.97270-0.85874-0.79000.h5\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.1280 - categorical_accuracy: 0.9231 - val_loss: 0.7658 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-12-2006_50_15.615578/model-00004-0.13642-0.94203-0.76579-0.74000.h5\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.0376 - categorical_accuracy: 0.9894 - val_loss: 0.6481 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-12-2006_50_15.615578/model-00005-0.05726-0.98093-0.64814-0.80000.h5\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.1133 - categorical_accuracy: 0.9217 - val_loss: 0.9932 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-12-2006_50_15.615578/model-00006-0.12642-0.93724-0.99317-0.64000.h5\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.0639 - categorical_accuracy: 0.9792 - val_loss: 0.7619 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-12-2006_50_15.615578/model-00007-0.08413-0.96825-0.76192-0.77000.h5\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.0717 - categorical_accuracy: 0.9419 - val_loss: 0.5643 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-12-2006_50_15.615578/model-00008-0.07596-0.96040-0.56428-0.79000.h5\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.0700 - categorical_accuracy: 0.9713 - val_loss: 0.7969 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-12-2006_50_15.615578/model-00009-0.08155-0.96699-0.79687-0.71000.h5\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.0366 - categorical_accuracy: 0.9512 - val_loss: 0.6648 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-12-2006_50_15.615578/model-00010-0.04428-0.96364-0.66479-0.77000.h5\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.0591 - categorical_accuracy: 0.9769 - val_loss: 0.5478 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-12-2006_50_15.615578/model-00011-0.06818-0.97284-0.54777-0.84000.h5\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 14s 989ms/step - loss: 0.0381 - categorical_accuracy: 0.9499 - val_loss: 0.9081 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-12-2006_50_15.615578/model-00012-0.03789-0.96094-0.90811-0.77000.h5\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 37s 3s/step - loss: 0.0801 - categorical_accuracy: 0.9642 - val_loss: 0.4313 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-12-2006_50_15.615578/model-00013-0.08415-0.96229-0.43134-0.85000.h5\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 10s 728ms/step - loss: 0.0333 - categorical_accuracy: 0.9549 - val_loss: 0.4732 - val_categorical_accuracy: 0.8900\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-12-2006_50_15.615578/model-00014-0.03715-0.95890-0.47318-0.89000.h5\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 36s 3s/step - loss: 0.0672 - categorical_accuracy: 0.9537 - val_loss: 0.5348 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-12-2006_50_15.615578/model-00015-0.07237-0.96965-0.53477-0.85000.h5\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.0475 - categorical_accuracy: 0.9777 - val_loss: 0.4690 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-12-2006_50_15.615578/model-00016-0.05363-0.97611-0.46895-0.83000.h5\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.0845 - categorical_accuracy: 0.9324 - val_loss: 0.5526 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-12-2006_50_15.615578/model-00017-0.08371-0.95833-0.55257-0.84000.h5\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.0398 - categorical_accuracy: 0.9970 - val_loss: 0.3294 - val_categorical_accuracy: 0.8600\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-12-2006_50_15.615578/model-00018-0.04340-0.99455-0.32940-0.86000.h5\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.0805 - categorical_accuracy: 0.9475 - val_loss: 0.5856 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-12-2006_50_15.615578/model-00019-0.07232-0.96862-0.58563-0.83000.h5\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.0744 - categorical_accuracy: 0.9723 - val_loss: 0.3522 - val_categorical_accuracy: 0.8600\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-12-2006_50_15.615578/model-00020-0.06800-0.97506-0.35220-0.86000.h5\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.0427 - categorical_accuracy: 0.9660 - val_loss: 0.4396 - val_categorical_accuracy: 0.8600\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-12-2006_50_15.615578/model-00021-0.05642-0.97525-0.43962-0.86000.h5\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.0678 - categorical_accuracy: 0.9839 - val_loss: 0.5333 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-12-2006_50_15.615578/model-00022-0.08499-0.97864-0.53334-0.84000.h5\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.1112 - categorical_accuracy: 0.9246 - val_loss: 0.5726 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-12-2006_50_15.615578/model-00023-0.08710-0.94848-0.57256-0.83000.h5\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.0423 - categorical_accuracy: 0.9870 - val_loss: 0.5244 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-12-2006_50_15.615578/model-00024-0.04696-0.98472-0.52439-0.84000.h5\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 13s 960ms/step - loss: 0.0352 - categorical_accuracy: 0.9629 - val_loss: 0.2641 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-12-2006_50_15.615578/model-00025-0.04117-0.96484-0.26414-0.90000.h5\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 37s 3s/step - loss: 0.0572 - categorical_accuracy: 0.9799 - val_loss: 0.5065 - val_categorical_accuracy: 0.8700\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-12-2006_50_15.615578/model-00026-0.05999-0.97888-0.50646-0.87000.h5\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 10s 726ms/step - loss: 0.0235 - categorical_accuracy: 0.9603 - val_loss: 0.5501 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-12-2006_50_15.615578/model-00027-0.02682-0.96347-0.55010-0.85000.h5\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 37s 3s/step - loss: 0.0705 - categorical_accuracy: 0.9508 - val_loss: 0.5679 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-12-2006_50_15.615578/model-00028-0.06915-0.96645-0.56793-0.84000.h5\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.0237 - categorical_accuracy: 0.9893 - val_loss: 0.3050 - val_categorical_accuracy: 0.9100\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-12-2006_50_15.615578/model-00029-0.02511-0.99317-0.30498-0.91000.h5\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.0236 - categorical_accuracy: 0.9627 - val_loss: 0.4976 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-12-2006_50_15.615578/model-00030-0.02452-0.98188-0.49763-0.83000.h5\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.0405 - categorical_accuracy: 0.9909 - val_loss: 0.5378 - val_categorical_accuracy: 0.8200\n",
      "\n",
      "Epoch 00031: saving model to model_init_2020-12-2006_50_15.615578/model-00031-0.05079-0.98365-0.53780-0.82000.h5\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.0590 - categorical_accuracy: 0.9528 - val_loss: 0.3395 - val_categorical_accuracy: 0.8900\n",
      "\n",
      "Epoch 00032: saving model to model_init_2020-12-2006_50_15.615578/model-00032-0.05668-0.97071-0.33946-0.89000.h5\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.0303 - categorical_accuracy: 0.9932 - val_loss: 0.3113 - val_categorical_accuracy: 0.9100\n",
      "\n",
      "Epoch 00033: saving model to model_init_2020-12-2006_50_15.615578/model-00033-0.02666-0.99546-0.31131-0.91000.h5\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.0317 - categorical_accuracy: 0.9614 - val_loss: 0.5799 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00034: saving model to model_init_2020-12-2006_50_15.615578/model-00034-0.03164-0.98020-0.57994-0.83000.h5\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.0595 - categorical_accuracy: 0.9851 - val_loss: 0.5512 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00035: saving model to model_init_2020-12-2006_50_15.615578/model-00035-0.04048-0.99029-0.55116-0.85000.h5\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.0671 - categorical_accuracy: 0.9543 - val_loss: 0.5413 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00036: saving model to model_init_2020-12-2006_50_15.615578/model-00036-0.05687-0.96970-0.54126-0.79000.h5\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.0475 - categorical_accuracy: 0.9817 - val_loss: 0.6289 - val_categorical_accuracy: 0.8200\n",
      "\n",
      "Epoch 00037: saving model to model_init_2020-12-2006_50_15.615578/model-00037-0.04904-0.98302-0.62895-0.82000.h5\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 13s 954ms/step - loss: 0.0170 - categorical_accuracy: 0.9661 - val_loss: 0.4894 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00038: saving model to model_init_2020-12-2006_50_15.615578/model-00038-0.02357-0.97266-0.48937-0.81000.h5\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 37s 3s/step - loss: 0.0328 - categorical_accuracy: 0.9900 - val_loss: 0.4721 - val_categorical_accuracy: 0.8900\n",
      "\n",
      "Epoch 00039: saving model to model_init_2020-12-2006_50_15.615578/model-00039-0.03443-0.98944-0.47212-0.89000.h5\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 10s 727ms/step - loss: 0.0204 - categorical_accuracy: 0.9674 - val_loss: 0.3376 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00040: saving model to model_init_2020-12-2006_50_15.615578/model-00040-0.02001-0.97260-0.33755-0.90000.h5\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 36s 3s/step - loss: 0.0506 - categorical_accuracy: 0.9565 - val_loss: 0.5934 - val_categorical_accuracy: 0.8300\n",
      "\n",
      "Epoch 00041: saving model to model_init_2020-12-2006_50_15.615578/model-00041-0.05096-0.97284-0.59339-0.83000.h5\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.0299 - categorical_accuracy: 0.9877 - val_loss: 0.4734 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00042: saving model to model_init_2020-12-2006_50_15.615578/model-00042-0.03461-0.98976-0.47337-0.85000.h5\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.0381 - categorical_accuracy: 0.9560 - val_loss: 0.5006 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00043: saving model to model_init_2020-12-2006_50_15.615578/model-00043-0.03198-0.97826-0.50064-0.84000.h5\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.0390 - categorical_accuracy: 0.9864 - val_loss: 0.5418 - val_categorical_accuracy: 0.7900\n",
      "\n",
      "Epoch 00044: saving model to model_init_2020-12-2006_50_15.615578/model-00044-0.04413-0.98910-0.54183-0.79000.h5\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.0277 - categorical_accuracy: 0.9566 - val_loss: 0.4016 - val_categorical_accuracy: 0.9200\n",
      "\n",
      "Epoch 00045: saving model to model_init_2020-12-2006_50_15.615578/model-00045-0.03610-0.97071-0.40160-0.92000.h5\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.0339 - categorical_accuracy: 0.9896 - val_loss: 0.3566 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00046: saving model to model_init_2020-12-2006_50_15.615578/model-00046-0.04716-0.98413-0.35658-0.90000.h5\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.0413 - categorical_accuracy: 0.9547 - val_loss: 0.3795 - val_categorical_accuracy: 0.8800\n",
      "\n",
      "Epoch 00047: saving model to model_init_2020-12-2006_50_15.615578/model-00047-0.03373-0.97525-0.37950-0.88000.h5\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0291 - categorical_accuracy: 0.9941 - val_loss: 0.3701 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00048: saving model to model_init_2020-12-2006_50_15.615578/model-00048-0.03115-0.99223-0.37012-0.90000.h5\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.0598 - categorical_accuracy: 0.9543 - val_loss: 0.4285 - val_categorical_accuracy: 0.8600\n",
      "\n",
      "Epoch 00049: saving model to model_init_2020-12-2006_50_15.615578/model-00049-0.04605-0.96970-0.42855-0.86000.h5\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.0323 - categorical_accuracy: 0.9890 - val_loss: 0.4266 - val_categorical_accuracy: 0.8800\n",
      "\n",
      "Epoch 00050: saving model to model_init_2020-12-2006_50_15.615578/model-00050-0.02809-0.99151-0.42655-0.88000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee9bfd0208>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5 is the best model, it has a validation loss ~0.4. The validation categorical loss is ~0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Model 6 we will add dropout in the 3D CNN Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = Sequential()\n",
    "model_6.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', padding = 'same', input_shape=input_shape))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_6.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Dropout(0.2))\n",
    "model_6.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_6.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Dropout(0.2))\n",
    "model_6.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_6.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Dropout(0.2))\n",
    "model_6.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "model_6.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu', padding = 'same'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Dropout(0.2))\n",
    "model_6.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "model_6.add(Flatten())\n",
    "model_6.add(Dropout(0.5))\n",
    "model_6.add(Dense(512, activation='relu'))\n",
    "model_6.add(Dropout(0.5))\n",
    "model_6.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_3 (Conv3D)            (None, 15, 120, 120, 32)  2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 120, 120, 32)  128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 7, 60, 60, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 7, 60, 60, 64)     55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 60, 60, 64)     256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 60, 60, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 3, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 3, 30, 30, 128)    221312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 3, 30, 30, 128)    512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 30, 30, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 1, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 1, 15, 15, 256)    884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 15, 15, 256)    1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 15, 15, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 1, 7, 7, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 1, 7, 7, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1, 7, 7, 256)      1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 7, 7, 256)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 1, 3, 3, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 4,119,685\n",
      "Trainable params: 4,118,213\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = RMSprop(lr=0.0005,clipvalue=1.0) #write your optimizer\n",
    "model_6.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_6.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalation = None\n",
    "train_generator = generator(train_path, train_doc, batch_size, abalation=abalation)\n",
    "val_generator = generator(val_path, val_doc, batch_size, abalation=abalation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=2, min_lr=0.00001)  # write the REducelronplateau code here\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (abalation%batch_size) == 0:\n",
    "#     steps_per_epoch = int(abalation/batch_size)\n",
    "# else:\n",
    "#     steps_per_epoch = (abalation//batch_size) + 1\n",
    "\n",
    "# if (abalation%batch_size) == 0:\n",
    "#     validation_steps = int(abalation/batch_size)\n",
    "# else:\n",
    "#     validation_steps = (abalation//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 50\n",
      "Source path =  Epoch 1/50\n",
      "Project_data/train ; batch size = 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  app.launch_new_instance()\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/14 [========================>.....] - ETA: 19s - loss: 4.8944 - categorical_accuracy: 0.2967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 128s 9s/step - loss: 4.6202 - categorical_accuracy: 0.3005 - val_loss: 6.0672 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2020-12-2112_08_23.269261/model-00001-4.72052-0.30015-6.06721-0.27000.h5\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 14s 982ms/step - loss: 0.8494 - categorical_accuracy: 0.7633 - val_loss: 5.4246 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00002: saving model to model_init_2020-12-2112_08_23.269261/model-00002-1.46100-0.65234-5.42460-0.43000.h5\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 42s 3s/step - loss: 1.7624 - categorical_accuracy: 0.4800 - val_loss: 5.4657 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00003: saving model to model_init_2020-12-2112_08_23.269261/model-00003-1.86472-0.47878-5.46574-0.28000.h5\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.7524 - categorical_accuracy: 0.8161 - val_loss: 5.0723 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00004: saving model to model_init_2020-12-2112_08_23.269261/model-00004-1.29190-0.69697-5.07234-0.36000.h5\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 36s 3s/step - loss: 1.3370 - categorical_accuracy: 0.5827 - val_loss: 8.2151 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00005: saving model to model_init_2020-12-2112_08_23.269261/model-00005-1.51786-0.54175-8.21513-0.29000.h5\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.9172 - categorical_accuracy: 0.7609 - val_loss: 6.8521 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00006: saving model to model_init_2020-12-2112_08_23.269261/model-00006-1.47201-0.62376-6.85211-0.27000.h5\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.7354 - categorical_accuracy: 0.7145 - val_loss: 5.8373 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00007: saving model to model_init_2020-12-2112_08_23.269261/model-00007-0.98889-0.65079-5.83726-0.35000.h5\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 38s 3s/step - loss: 0.6866 - categorical_accuracy: 0.7797 - val_loss: 4.3110 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00008: saving model to model_init_2020-12-2112_08_23.269261/model-00008-0.95529-0.69247-4.31100-0.36000.h5\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.4792 - categorical_accuracy: 0.7916 - val_loss: 4.2425 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00009: saving model to model_init_2020-12-2112_08_23.269261/model-00009-0.75601-0.71390-4.24247-0.35000.h5\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.5882 - categorical_accuracy: 0.8037 - val_loss: 2.2680 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00010: saving model to model_init_2020-12-2112_08_23.269261/model-00010-0.72723-0.75543-2.26801-0.53000.h5\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.3934 - categorical_accuracy: 0.8354 - val_loss: 5.9225 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00011: saving model to model_init_2020-12-2112_08_23.269261/model-00011-0.63376-0.76451-5.92249-0.27000.h5\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 36s 3s/step - loss: 0.6799 - categorical_accuracy: 0.7682 - val_loss: 5.9545 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00012: saving model to model_init_2020-12-2112_08_23.269261/model-00012-0.75015-0.74281-5.95452-0.32000.h5\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 10s 749ms/step - loss: 0.2379 - categorical_accuracy: 0.8956 - val_loss: 5.3877 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00013: saving model to model_init_2020-12-2112_08_23.269261/model-00013-0.32913-0.86758-5.38770-0.36000.h5\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 39s 3s/step - loss: 0.6061 - categorical_accuracy: 0.7702 - val_loss: 5.5603 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00014: saving model to model_init_2020-12-2112_08_23.269261/model-00014-0.62416-0.77828-5.56026-0.32000.h5\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 12s 854ms/step - loss: 0.1125 - categorical_accuracy: 0.9422 - val_loss: 4.4509 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00015: saving model to model_init_2020-12-2112_08_23.269261/model-00015-0.20386-0.91406-4.45087-0.38000.h5\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 36s 3s/step - loss: 0.4860 - categorical_accuracy: 0.7814 - val_loss: 2.9877 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00016: saving model to model_init_2020-12-2112_08_23.269261/model-00016-0.48741-0.80136-2.98769-0.42000.h5\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.1962 - categorical_accuracy: 0.9310 - val_loss: 4.2281 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00017: saving model to model_init_2020-12-2112_08_23.269261/model-00017-0.33482-0.87879-4.22812-0.34000.h5\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.3844 - categorical_accuracy: 0.8173 - val_loss: 4.8542 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2020-12-2112_08_23.269261/model-00018-0.41418-0.83301-4.85420-0.40000.h5\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 21s 1s/step - loss: 0.2037 - categorical_accuracy: 0.9371 - val_loss: 5.7690 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2020-12-2112_08_23.269261/model-00019-0.32171-0.89604-5.76901-0.35000.h5\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.1653 - categorical_accuracy: 0.9154 - val_loss: 3.9166 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00020: saving model to model_init_2020-12-2112_08_23.269261/model-00020-0.18891-0.92290-3.91664-0.40000.h5\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1616 - categorical_accuracy: 0.9291 - val_loss: 3.9471 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00021: saving model to model_init_2020-12-2112_08_23.269261/model-00021-0.20562-0.91004-3.94713-0.42000.h5\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.2132 - categorical_accuracy: 0.8992 - val_loss: 4.4256 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00022: saving model to model_init_2020-12-2112_08_23.269261/model-00022-0.26700-0.89373-4.42557-0.32000.h5\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.1859 - categorical_accuracy: 0.9351 - val_loss: 3.4953 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00023: saving model to model_init_2020-12-2112_08_23.269261/model-00023-0.22148-0.92391-3.49525-0.44000.h5\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.1719 - categorical_accuracy: 0.9308 - val_loss: 3.2280 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00024: saving model to model_init_2020-12-2112_08_23.269261/model-00024-0.16565-0.93174-3.22800-0.46000.h5\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.1750 - categorical_accuracy: 0.9338 - val_loss: 2.7350 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00025: saving model to model_init_2020-12-2112_08_23.269261/model-00025-0.19123-0.92652-2.73500-0.52000.h5\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 10s 747ms/step - loss: 0.0939 - categorical_accuracy: 0.9370 - val_loss: 3.3576 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00026: saving model to model_init_2020-12-2112_08_23.269261/model-00026-0.09371-0.94064-3.35755-0.42000.h5\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 36s 3s/step - loss: 0.2312 - categorical_accuracy: 0.8912 - val_loss: 2.2829 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00027: saving model to model_init_2020-12-2112_08_23.269261/model-00027-0.22010-0.90950-2.28289-0.57000.h5\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 12s 861ms/step - loss: 0.1300 - categorical_accuracy: 0.9366 - val_loss: 1.6582 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00028: saving model to model_init_2020-12-2112_08_23.269261/model-00028-0.13962-0.93750-1.65820-0.65000.h5\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.1300 - categorical_accuracy: 0.9132 - val_loss: 1.8435 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00029: saving model to model_init_2020-12-2112_08_23.269261/model-00029-0.13288-0.93379-1.84352-0.64000.h5\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.0689 - categorical_accuracy: 0.9793 - val_loss: 1.8139 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00030: saving model to model_init_2020-12-2112_08_23.269261/model-00030-0.09890-0.96667-1.81388-0.65000.h5\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.1544 - categorical_accuracy: 0.9164 - val_loss: 1.6543 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00031: saving model to model_init_2020-12-2112_08_23.269261/model-00031-0.16313-0.92427-1.65432-0.65000.h5\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.0990 - categorical_accuracy: 0.9616 - val_loss: 1.5141 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00032: saving model to model_init_2020-12-2112_08_23.269261/model-00032-0.11277-0.95545-1.51410-0.67000.h5\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.1691 - categorical_accuracy: 0.9282 - val_loss: 1.5324 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00033: saving model to model_init_2020-12-2112_08_23.269261/model-00033-0.19187-0.92517-1.53242-0.71000.h5\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1117 - categorical_accuracy: 0.9526 - val_loss: 1.4925 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00034: saving model to model_init_2020-12-2112_08_23.269261/model-00034-0.13692-0.94351-1.49253-0.71000.h5\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.0966 - categorical_accuracy: 0.9409 - val_loss: 1.5185 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00035: saving model to model_init_2020-12-2112_08_23.269261/model-00035-0.12988-0.94823-1.51848-0.68000.h5\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.1071 - categorical_accuracy: 0.9624 - val_loss: 1.4503 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00036: saving model to model_init_2020-12-2112_08_23.269261/model-00036-0.09978-0.96739-1.45030-0.70000.h5\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1203 - categorical_accuracy: 0.9340 - val_loss: 1.2303 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00037: saving model to model_init_2020-12-2112_08_23.269261/model-00037-0.12160-0.93857-1.23031-0.73000.h5\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 35s 2s/step - loss: 0.1626 - categorical_accuracy: 0.9368 - val_loss: 1.0127 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00038: saving model to model_init_2020-12-2112_08_23.269261/model-00038-0.15367-0.94249-1.01273-0.75000.h5\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 10s 747ms/step - loss: 0.0708 - categorical_accuracy: 0.9658 - val_loss: 1.1292 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00039: saving model to model_init_2020-12-2112_08_23.269261/model-00039-0.06931-0.96804-1.12923-0.77000.h5\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 37s 3s/step - loss: 0.1403 - categorical_accuracy: 0.9399 - val_loss: 1.1096 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00040: saving model to model_init_2020-12-2112_08_23.269261/model-00040-0.14526-0.94872-1.10964-0.75000.h5\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 13s 940ms/step - loss: 0.1344 - categorical_accuracy: 0.9505 - val_loss: 1.0769 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00041: saving model to model_init_2020-12-2112_08_23.269261/model-00041-0.13550-0.95313-1.07687-0.74000.h5\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 35s 2s/step - loss: 0.1227 - categorical_accuracy: 0.9434 - val_loss: 1.1361 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00042: saving model to model_init_2020-12-2112_08_23.269261/model-00042-0.11783-0.95586-1.13613-0.72000.h5\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.0574 - categorical_accuracy: 0.9771 - val_loss: 1.1602 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00043: saving model to model_init_2020-12-2112_08_23.269261/model-00043-0.08036-0.96970-1.16019-0.74000.h5\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.0963 - categorical_accuracy: 0.9468 - val_loss: 1.1083 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00044: saving model to model_init_2020-12-2112_08_23.269261/model-00044-0.11675-0.94951-1.10827-0.74000.h5\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.0641 - categorical_accuracy: 0.9805 - val_loss: 1.1270 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00045: saving model to model_init_2020-12-2112_08_23.269261/model-00045-0.09406-0.96782-1.12699-0.73000.h5\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1292 - categorical_accuracy: 0.9144 - val_loss: 1.1280 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00046: saving model to model_init_2020-12-2112_08_23.269261/model-00046-0.11719-0.93878-1.12802-0.75000.h5\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.0832 - categorical_accuracy: 0.9762 - val_loss: 1.1708 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00047: saving model to model_init_2020-12-2112_08_23.269261/model-00047-0.08119-0.97699-1.17079-0.72000.h5\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 21s 2s/step - loss: 0.0688 - categorical_accuracy: 0.9462 - val_loss: 1.1143 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00048: saving model to model_init_2020-12-2112_08_23.269261/model-00048-0.08595-0.95095-1.11429-0.74000.h5\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.0908 - categorical_accuracy: 0.9729 - val_loss: 1.0763 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00049: saving model to model_init_2020-12-2112_08_23.269261/model-00049-0.10219-0.97101-1.07628-0.74000.h5\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1603 - categorical_accuracy: 0.9103 - val_loss: 1.0163 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00050: saving model to model_init_2020-12-2112_08_23.269261/model-00050-0.13197-0.92833-1.01632-0.75000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a6a962978>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This model has a validation accuracy of ~0.75 and validation loss of ~1.1. The model is less effective than the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model:\n",
    "## Model 5 is the final model. The model has validation accuracies ~0.9. The best epoch has a 0.92 accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
